{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139b6d98-b350-4ef9-a824-88b6d2e3ff34",
   "metadata": {},
   "source": [
    "# Mistral Guanoca LoRA PEFT example\n",
    "\n",
    "Source Article: https://www.datacamp.com/tutorial/mistral-7b-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b13958e-c4bc-4ff8-9e26-003f9309f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: torch in /home/user/envs/test_env/lib/python3.10/site-packages (from bitsandbytes) (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/user/envs/test_env/lib/python3.10/site-packages (from bitsandbytes) (1.26.2)\n",
      "Requirement already satisfied: filelock in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/envs/test_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/envs/test_env/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.0\n",
      "Requirement already satisfied: transformers in /home/user/envs/test_env/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting peft\n",
      "  Using cached peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (2.2.1)\n",
      "Requirement already satisfied: transformers in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (0.28.0)\n",
      "Requirement already satisfied: safetensors in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from peft) (0.19.4)\n",
      "Requirement already satisfied: filelock in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/envs/test_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.2.140)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers->peft) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/envs/test_env/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.9.0-py3-none-any.whl (190 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.9.0\n",
      "Requirement already satisfied: accelerate in /home/user/envs/test_env/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/envs/test_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.2.140)\n",
      "Requirement already satisfied: requests in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/envs/test_env/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from trl) (2.2.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from trl) (4.38.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/user/envs/test_env/lib/python3.10/site-packages (from trl) (1.26.2)\n",
      "Requirement already satisfied: accelerate in /home/user/envs/test_env/lib/python3.10/site-packages (from trl) (0.28.0)\n",
      "Requirement already satisfied: datasets in /home/user/envs/test_env/lib/python3.10/site-packages (from trl) (2.18.0)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Using cached tyro-0.7.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/envs/test_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.2.140)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/envs/test_env/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.1)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /home/user/envs/test_env/lib/python3.10/site-packages (from accelerate->trl) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/user/envs/test_env/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/envs/test_env/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/envs/test_env/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/envs/test_env/lib/python3.10/site-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/user/envs/test_env/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/envs/test_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/envs/test_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading trl-0.8.0-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tyro-0.7.3-py3-none-any.whl (79 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, docstring-parser, tyro, trl\n",
      "Successfully installed docstring-parser-0.16 shtab-1.7.1 trl-0.8.0 tyro-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U peft\n",
    "!pip install -U accelerate\n",
    "!pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89e65d2-d0ef-428a-9582-537ff3784f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/envs/test_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.41s/it]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 21:02:55.278734: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 21:02:55.278768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 21:02:55.279807: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 21:02:55.284765: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 21:02:55.811000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   733, 16289, 28793,  1824,   349,   574, 16020,  2076,  2487,\n",
      "        28804,   733, 28748, 16289, 28793,  6824, 28725,   315, 28742, 28719,\n",
      "         3448, 10473,   298,   264,  1179, 11322, 19961,   302,  6138, 23598,\n",
      "        18342, 28723,   661, 13633,   776,   272,  1103,  3558,   302,   686,\n",
      "        16944, 15637,   423,   298,  5681,   315, 28742, 28719, 13198,   582,\n",
      "          297,   272,  6132, 28808,     2, 28705,   733, 16289, 28793,  2378,\n",
      "          368,   506,   993,  7136,   864, 21116, 28804,   733, 28748, 16289,\n",
      "        28793])\n",
      "<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s>  [INST] Do you have mayonnaise recipes? [/INST] Certainly! Here's a simple recipe for a classic mayonnaise that you can whip up at home:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 2 large egg yolks\n",
      "* 1 tablespoon Dijon mustard\n",
      "* 2 tablespoons white wine vinegar\n",
      "* 1/2 cup vegetable oil\n",
      "* Salt and pepper to taste\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. In a small bowl, whisk together the egg yolks, Dijon mustard, and white wine vinegar until well combined.\n",
      "2. Slowly drizzle in the vegetable oil while whisking continuously.\n",
      "3. Continue whisking until the mixture thickens and emulsifies.\n",
      "4. Season to taste with salt and pepper.\n",
      "\n",
      "That's it! Once you've mastered the basic mayonnaise recipe, you can experiment with different variations, like adding herbs or spices for a unique twist. And if you want to make an aioli (a garlic mayonnaise), simply add mashed garlic to the mixture if you love the taste of garlic!</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s>  [INST] Do you have mayonnaise recipes? [/INST] Certainly! Here's a simple recipe for a classic mayonnaise that you can whip up at home:\\n\\nIngredients:\\n\\n* 2 large egg yolks\\n* 1 tablespoon Dijon mustard\\n* 2 tablespoons white wine vinegar\\n* 1/2 cup vegetable oil\\n* Salt and pepper to taste\\n\\nInstructions:\\n\\n1. In a small bowl, whisk together the egg yolks, Dijon mustard, and white wine vinegar until well combined.\\n2. Slowly drizzle in the vegetable oil while whisking continuously.\\n3. Continue whisking until the mixture thickens and emulsifies.\\n4. Season to taste with salt and pepper.\\n\\nThat's it! Once you've mastered the basic mayonnaise recipe, you can experiment with different variations, like adding herbs or spices for a unique twist. And if you want to make an aioli (a garlic mayonnaise), simply add mashed garlic to the mixture if you love the taste of garlic!</s>\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "#model_name=\"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(  \n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True\n",
    "                                            )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          trust_remote_code=True,\n",
    "                                          device_map=\"auto\"\n",
    "                                         )\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "print(tokenizer.add_bos_token, tokenizer.add_eos_token)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "]\n",
    "\n",
    "\n",
    "model.config.use_cache = False # silence the warnings\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "def chat(messages):\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "    \n",
    "    model_inputs = encodeds.to(torch.cuda.current_device())\n",
    "    \n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=2000, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    print(encodeds[0])\n",
    "    print(decoded[0])\n",
    "    return decoded[0]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedad57b-1414-48e1-9d32-d4f1315f6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd \n",
    "\n",
    "# df=pd.read_csv('gemma1000_w7b.csv')\n",
    "\n",
    "# df.columns\n",
    "ds = load_dataset(\"csv\",data_files={\"train\":'gemma1000_w7b.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815cd33e-f94f-4076-902e-8ec1dab1b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['original_text','gemma_7b_rewritten_text_temp0','rewrite_prompt']]\n",
    "# df['diff_prompt']='Tell me what prompt converted the following text: \\n\"\"\"' + df['original_text'] + '\"\"\"\\n to this text \\n\"\"\"' + df['gemma_7b_rewritten_text_temp0'] + '\"\"\"\\n'\n",
    "#original text prefix\n",
    "import json\n",
    "\n",
    "orig_prefix = \"Original Text: \"\n",
    "\n",
    "#mistral \"response\"\n",
    "llm_response_for_rewrite = \"Provide the modified text and I'll tell you a something general that changed about it.  I'll avoid any specifics though.  My tone will be neutral.\"\n",
    "\n",
    "#modified text prefix\n",
    "rewrite_prefix = \"Rewritten Text: \"\n",
    "\n",
    "#provided as start of Mistral response (anything after this is used as the prompt)\n",
    "#providing this as the start of the response helps keep things relevant\n",
    "response_start = \"The request was: \"\n",
    "\n",
    "#We insert our detected prompt into this well-scoring baseline text\n",
    "#thanks to: https://www.kaggle.com/code/rdxsun/lb-0-61\n",
    "base_line = 'Refine the following passage by emulating the writing style of [insert desired style here], with a focus on enhancing its clarity, elegance, and overall impact. Preserve the essence and original meaning of the text, while meticulously adjusting its tone, vocabulary, and stylistic elements to resonate with the chosen style.Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.' \n",
    "base_line_swap_text = \"[insert desired style here]\"\n",
    "\n",
    "# this function is used to output the right formate for each row in the dataset\n",
    "def create_text_row(instruction, output) -> str:\n",
    "    if output is not None:\n",
    "        text_row = f\"\"\"<s>[INST] {instruction} [/INST] \\\\n {response_start} {output} </s>\"\"\"\n",
    "    else:\n",
    "        text_row = f\"\"\"<s>[INST] {instruction} [/INST] \\\\n {response_start}\"\"\"\n",
    "    return text_row\n",
    "\n",
    "\n",
    "def get_prompt(orig_text, transformed_text, rewritten_text = None):\n",
    "    if rewritten_text is None:\n",
    "        message = create_text_row(f\"{orig_prefix} {orig_text}\",llm_response_for_rewrite) + create_text_row(f\" {rewrite_prefix} {transformed_text}\", None)\n",
    "    else:\n",
    "        message = create_text_row(f\"{orig_prefix} {orig_text}\",llm_response_for_rewrite) + create_text_row(f\" {rewrite_prefix} {transformed_text}\",{rewritten_text})\n",
    "    return message\n",
    "\n",
    "\n",
    "# interate over all the rows formate the dataset and store it in a jsonl file\n",
    "def process_jsonl_file(output_file_path):\n",
    "    with open(output_file_path, \"w\") as output_jsonl_file:\n",
    "        for item in ds[\"train\"]:\n",
    "            json_object = {\n",
    "                \"text\": get_prompt(item[\"original_text\"],item['gemma_7b_rewritten_text_temp0'],item['prompt'])\n",
    "            }\n",
    "            output_jsonl_file.write(json.dumps(json_object) + \"\\n\")\n",
    "\n",
    "# Provide the path where you want to save the formatted dataset\n",
    "process_jsonl_file(\"./training_dataset.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac41d4be-7887-46c8-a18d-480790dbe2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:00, 97535.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('json', data_files='./training_dataset.jsonl' , split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093ab2f1-d71e-43ed-ae56-0ca366a75287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(x):\n",
    "#     model_inputs = tokenizer.apply_chat_template(x, return_tensors=\"pt\")    \n",
    "#     generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "#     decoded = tokenizer.batch_decode(generated_ids)\n",
    "#     return decoded\n",
    "\n",
    "# for i,r in df.iterrows():\n",
    "#     message=[\n",
    "#     {\"role\": \"user\", \"content\": r['original_text']},\n",
    "#     {\"role\": \"assistant\", \"content\": r[\n",
    "#     ]\n",
    "#     df.at[i, 'predicted_prompt']=chat(message)\n",
    "#     print(df.at[i, 'predicted_prompt'])\n",
    "#     if (i>5):\n",
    "#         break\n",
    "\n",
    "# df.iloc[0:6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f109dc69-0bcc-499c-b3e5-63570fc673d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da41dc8-f7b0-4703-8613-a8c7018726fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\",]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af4f26a-1c12-47ae-b6cd-20a9e5fe6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_total_limit = 2, \n",
    "    save_strategy = \"no\", \n",
    "    load_best_model_at_end=False,\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c743de9-b60c-4b26-a7f4-062561b64e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/envs/test_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5462.92 examples/s]\n",
      "/home/user/envs/test_env/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a27ea0-ddb2-451e-ab5b-23da781a745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/envs/test_env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 30:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.941300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.884100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.889700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.886100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.884200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.659100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.560100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/envs/test_env/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "new_model='Mistral-7b-instruct-v0.1-qlora'\n",
    "#new_model='Mistral-7b-v0.1-qlora'\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(new_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf982bc7-4e7a-471e-a8d7-9716b01822cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.47s/it]\n",
      "/home/user/envs/test_env/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:272: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('merged_model/tokenizer_config.json',\n",
       " 'merged_model/special_tokens_map.json',\n",
       " 'merged_model/tokenizer.model',\n",
       " 'merged_model/added_tokens.json',\n",
       " 'merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the model with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16, #bfloat and float?\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "merged_model= PeftModel.from_pretrained(base_model, new_model)\n",
    "merged_model= model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "merged_model.save_pretrained(\"merged_model\",safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff820a3-8538-476a-a637-0b73eed11029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c814bf9-ab0b-457a-a6d5-386a553494a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/envs/test_env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/user/envs/test_env/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] How do I find true love? [/INST] Finding true love is a journey that requires time, effort, and self-discovery. Here are some steps to help you on your journey:\n",
      "\n",
      "1. Focus on yourself: Before you can find true love, you need to focus on yourself and your own happiness. This means taking care of your physical, emotional, and mental well-being.\n",
      "2. Set boundaries: It's important to set boundaries for yourself and communicate them clearly to potential partners. This includes setting boundaries for your time, your space, and your expectations.\n",
      "3. Be open to new experiences: Don't be afraid to try new things and meet new people. This can help you expand your horizons and increase your chances of finding true love.\n",
      "4. Be patient: Finding true love takes time, so be patient and don't rush the process.\n",
      "5. Be honest and authentic: Be yourself\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "prompt = \"How do I find true love?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=merged_model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f65d243-91bc-43c5-b91c-81bb0fe0556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is Datacamp Career track? [/INST] The Datacamp Career Track is a program that provides a comprehensive learning path for individuals who want to become data scientists. It includes a series of courses, projects, and assessments that cover a wide range of topics in data science, including statistics, programming, machine learning, and data visualization.\n",
      "\n",
      "The program is designed to be flexible and self-paced, allowing learners to progress at their own speed. It also includes a variety of interactive elements, such as quizzes, coding challenges, and projects, to help learners apply their knowledge and skills in practical ways.\n",
      "\n",
      "Upon completion of the program, learners will receive a certificate from Datacamp, which can be used to demonstrate their proficiency in data science to potential employers. The program is also designed to prepare learners for the Data Science Certification exam offered by the International Institute of Analytics (IIA).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is Datacamp Career track?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8117814-7775-4b39-9bd7-e9a6abd2ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is stochastic gradient descent? [/INST] Stochastic gradient descent (SGD) is an optimization algorithm commonly used to train machine learning models. It is a variation of the standard gradient descent algorithm, which is used to minimize the cost function of a model by iteratively adjusting its parameters.\n",
      "\n",
      "The key difference between standard gradient descent and stochastic gradient descent is the way the gradient is calculated. In standard gradient descent, the gradient is calculated using the entire training set, which can be computationally expensive, especially for large datasets. In contrast, stochastic gradient descent calculates the gradient using a random subset of the training data, which is typically much smaller and faster to compute.\n",
      "\n",
      "This allows SGD to converge more quickly and efficiently than standard gradient descent, especially for large datasets. Additionally, SGD is less sensitive to the presence of outliers in the data, which can help improve the stability of the training process.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is stochastic gradient descent?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a42fbc-b75b-4c7b-b766-ac272afae12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "<s>[INST] Original Text:  Panhandler Lawsuit Kim Pindak stands outside Chicago's federal courthouse after the first day of testimony in a civil lawsuit involving him and and other panhandlers Monday, Jan. 25, 2016, in Chicago. He and another panhandler brought a suit that alleges they lost up to $10 a day because authorities bar them from begging in Daley Plaza, a popular public square in the city. The trial that started today is a rare instance of jurors being asked to decide the issue of panhandlers' rights. (AP Photo/Michael Tarm) CHICAGO -- A federal civil trial pitting two panhandlers against one of the nation's [/INST] \\n The request was:  Provide the modified text and I'll tell you a something general that changed about it.  I'll avoid any specifics though.  My tone will be neutral. </s><s>[INST]  Rewritten Text:  ## Public Service Announcement\n",
      "\n",
      "**Attention, Chicago residents:**\n",
      "\n",
      "This public service announcement brings awareness to a ongoing case involving panhandlers and the City of Chicago.\n",
      "\n",
      "The case, which began today, January 25th, involves two panhandlers, Kim Pindak and another unnamed individual, who are challenging a city ordinance that prohibits begging in Daley Plaza.\n",
      "\n",
      "The lawsuit alleges that the ordinance unfairly targets panhandlers while leaving other forms of street vendors untouched. It also claims that the ordinance has resulted in a loss of income for the plaintiffs, with some estimating a daily loss of up to $10.\n",
      "\n",
      "This case presents a unique opportunity for jurors to weigh the rights of panhandlers against the city's interest in maintaining public safety and order. It is a rare instance where jurors will be asked to decide the complex issue of panhandlers' rights and the boundaries of free speech and public space.\n",
      "\n",
      "The trial is ongoing, and the outcome could have a significant impact on the future of panhandling in Chicago. Stay tuned for further updates and information on the case. [/INST] \\n The request was: \n",
      "\n",
      "\n",
      "Generated instruction:\n",
      "Rewritten Text:  ## Public Service Announcement\n",
      "\n",
      "**Attention, Chicago residents:**\n",
      "\n",
      "This public service announcement brings awareness to a ongoing case involving panhandlers and the City of Chicago.\n",
      "\n",
      "The case, which began today, January 25th, involves two panhandlers, Kim Pindak and another unnamed individual, who are challenging a city ordinance that prohibits begging in Daley Plaza.\n",
      "\n",
      "\n",
      "\n",
      "Ground truth:\n",
      "Imagine this as a public service announcement.\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "sample = ds[\"train\"][randrange(len(train_dataset ))]\n",
    "\n",
    "prompt = get_prompt(sample[\"original_text\"],sample['gemma_7b_rewritten_text_temp0'])\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "# with torch.inference_mode():\n",
    "outputs = merged_model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=True, top_p=0.9,temperature=0.5)\n",
    "\n",
    "print(f\"Prompt:\\n{prompt}\\n\")\n",
    "print(f\"\\nGenerated instruction:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]}\")\n",
    "print(f\"\\nGround truth:\\n{sample['rewrite_prompt']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6528325-0f19-45d7-b1b2-864274dfa51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
